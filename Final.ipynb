{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shravan1994/shravan1994/blob/main/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lL80PmlJl5nB"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ExQJXGCasxx"
      },
      "source": [
        "## Mounting drive and copying the model_training.ipynb file from drive \n",
        "<p>This file contains few methods to build a features, which we want to reuse in this file</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2o8iPJKGuqSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b058f42c-fca3-4e70-e44e-c9c682e77c6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[NbConvertApp] Converting notebook model_training.ipynb to python\n",
            "[NbConvertApp] Writing 34630 bytes to model_training.py\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Collecting xgboost\n",
            "  Downloading xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl (192.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 192.9 MB 50 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n",
            "Installing collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed xgboost-1.6.1\n",
            "Is events data available?    What we are predicting?                                               Test log loss\n",
            "---------------------------  ------------------------------------------------------------------  ---------------\n",
            "Yes                          Gender                                                                     0.491647\n",
            "Yes                          User group (used predicted gender from above model as new feature)         2.1338\n",
            "No                           Gender                                                                     0.651126\n",
            "No                           User group (used predicted gender from above model as new feature)         2.42014\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp '/content/drive/MyDrive/Colab Notebooks/Self case study/Talking Data User Demographics Prediction/submissions/model_training.ipynb' .\n",
        "\n",
        "!jupyter nbconvert 'model_training.ipynb' --to python\n",
        "\n",
        "# after running this file, all it's functions will be availble in current file to run.\n",
        "# import model_training.ipynb\n",
        "import model_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d0v1M6eidKLo"
      },
      "outputs": [],
      "source": [
        "# drive path to load models from\n",
        "drive_path = '/content/drive/MyDrive/Colab Notebooks/Self case study/Talking Data User Demographics Prediction/models'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URWGF41jaYr-"
      },
      "source": [
        "## Downloading data from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M_FnxVKMDs-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82510549-96f5-4fbc-c480-b374a0b4d0f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 ./kaggle.json'\n",
            "Downloading talkingdata-mobile-user-demographics.zip to /content\n",
            " 95% 268M/283M [00:01<00:00, 163MB/s]\n",
            "100% 283M/283M [00:01<00:00, 162MB/s]\n",
            "Archive:  /content/talkingdata-mobile-user-demographics.zip\n",
            "  inflating: app_events.csv.zip      \n",
            "  inflating: app_labels.csv.zip      \n",
            "  inflating: events.csv.zip          \n",
            "  inflating: gender_age_test.csv.zip  \n",
            "  inflating: gender_age_train.csv.zip  \n",
            "  inflating: label_categories.csv.zip  \n",
            "  inflating: phone_brand_device_model.csv.zip  \n",
            "  inflating: sample_submission.csv.zip  \n",
            "Archive:  /content/app_events.csv.zip\n",
            "  inflating: data/app_events.csv     \n",
            "Archive:  /content/app_labels.csv.zip\n",
            "  inflating: data/app_labels.csv     \n",
            "Archive:  /content/events.csv.zip\n",
            "  inflating: data/events.csv         \n",
            "Archive:  /content/gender_age_test.csv.zip\n",
            "  inflating: data/gender_age_test.csv  \n",
            "Archive:  /content/gender_age_train.csv.zip\n",
            "  inflating: data/gender_age_train.csv  \n",
            "Archive:  /content/label_categories.csv.zip\n",
            "  inflating: data/label_categories.csv  \n",
            "Archive:  /content/phone_brand_device_model.csv.zip\n",
            "  inflating: data/phone_brand_device_model.csv  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \".\"\n",
        "\n",
        "!kaggle competitions download -c talkingdata-mobile-user-demographics\n",
        "\n",
        "!unzip '/content/talkingdata-mobile-user-demographics.zip'\n",
        "!unzip '/content/app_events.csv.zip' -d data\n",
        "!unzip '/content/app_labels.csv.zip' -d data\n",
        "!unzip '/content/events.csv.zip' -d data\n",
        "!unzip '/content/gender_age_test.csv.zip' -d data\n",
        "!unzip '/content/gender_age_train.csv.zip' -d data\n",
        "!unzip '/content/label_categories.csv.zip' -d data\n",
        "!unzip '/content/phone_brand_device_model.csv.zip' -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fS5TafGazKyp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from geopy.distance import geodesic, great_circle\n",
        "from scipy.sparse import hstack, save_npz\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bGIRaMH5UPe3"
      },
      "outputs": [],
      "source": [
        "def select_k_best_(features, label, n=1000, training=False):\n",
        "  from sklearn.feature_selection import SelectKBest, chi2\n",
        "  import pickle\n",
        "  filename = f'{drive_path}/select_k_best_{label}.pkl'\n",
        "\n",
        "  kbest = pickle.load(open(filename, 'rb'))\n",
        "  best_features = kbest.transform(features)\n",
        "  return best_features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This method encodes the target labels and returns the same"
      ],
      "metadata": {
        "id": "FIFx1KBstyWX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OmFrPLeFqdzP"
      },
      "outputs": [],
      "source": [
        "def get_labels_(y, label='group', inverse=False):\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  import pickle\n",
        "\n",
        "  filename = f'{drive_path}/label_encoder_{label}.pkl'\n",
        "  enc = pickle.load(open(filename, 'rb'))\n",
        "  if inverse:\n",
        "    y = enc.inverse_transform(y)\n",
        "  else:\n",
        "    y =  enc.transform(y)\n",
        "  return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja1nInmgcCCh"
      },
      "source": [
        "## This method returns the all features, based on weather it has events or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A22XPKlJHc2-"
      },
      "outputs": [],
      "source": [
        "def get_features(devices_data, raw_data_dict, label, has_events=False):\n",
        "  all_events_df = raw_data_dict.get('all_events')\n",
        "  all_app_events_df = raw_data_dict.get('all_app_events')\n",
        "  app_labels_df = raw_data_dict.get('app_labels')\n",
        "  label_categories_df = raw_data_dict.get('label_categories')\n",
        "  phone_brand_df = raw_data_dict.get('phone_brand')\n",
        "  \n",
        "  phone_brand_resp_enc = model_training.get_phone_brand_features_response_enc(\n",
        "      devices_data, phone_brand_df, None, label=f'{label}_no_events', training=False)\n",
        "  device_model_resp_enc = model_training.get_device_model_features_response_enc(\n",
        "      devices_data, phone_brand_df, None, label=f'{label}_no_events', training=False)\n",
        "  bow_phone_brand = model_training.get_phone_brand_features_bow(devices_data, phone_brand_df, training=False)\n",
        "  bow_device_model = model_training.get_device_model_features_bow(devices_data, phone_brand_df, training=False)\n",
        "  \n",
        "  if not has_events:\n",
        "    X = hstack([bow_phone_brand, bow_device_model, phone_brand_resp_enc, device_model_resp_enc])\n",
        "    \n",
        "    print('data shape before removing no var data: ', X.shape)\n",
        "    X = model_training.remove_features_with_no_variance(X, training=False, label=f'{label}_no_events')\n",
        "    print('data shape', X.shape)\n",
        "    return X\n",
        "  else:\n",
        "    categories_bow = model_training.get_bag_of_categories(\n",
        "      devices_data, all_events_df, all_app_events_df, \n",
        "      app_labels_df, label_categories_df, training=False\n",
        "    )\n",
        "    \n",
        "    apps_bow = model_training.get_bag_of_apps(devices_data, app_labels_df, all_events_df, all_app_events_df, label_categories_df, training=False)\n",
        "    \n",
        "    total_events = model_training.get_total_events(devices_data, all_events_df, training=False)\n",
        "    total_apps = model_training.total_apps_installed(devices_data, all_events_df, all_app_events_df, training=False)\n",
        "    distance_travelled = model_training.distance_traveled_per_day(devices_data, all_events_df, training=False)\n",
        "    median_lat_long = model_training.get_median_lat_long(devices_data, all_events_df)\n",
        "    hourly_events = model_training.get_hourly_events(devices_data, all_events_df)\n",
        "    \n",
        "    apps_bow_best = select_k_best_(apps_bow, label=label, n=2000, training=False)\n",
        "\n",
        "    X = hstack([categories_bow, apps_bow_best, \n",
        "            bow_phone_brand, bow_device_model, \n",
        "            total_apps, distance_travelled, median_lat_long, hourly_events])\n",
        "\n",
        "    print('data shape before removing no variance data: ', X.shape)\n",
        "    X = model_training.remove_features_with_no_variance(X, training=False, label=f'{label}_with_events')\n",
        "    print('data shape', X.shape)\n",
        "  \n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We use the existing trained model to predict gender on devices with events data"
      ],
      "metadata": {
        "id": "0jDb98qIuWGw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4XBQR4w4TAsf"
      },
      "outputs": [],
      "source": [
        "def predict_gender_with_events(devices_with_events, raw_data_dict):\n",
        "  print('Predicting gender using events data')\n",
        "  import pickle\n",
        "  file_name = f\"{drive_path}/best_model_gender_with_events.pkl\"\n",
        "  cali_cfl = pickle.load(open(file_name, \"rb\"))\n",
        "\n",
        "  X_data = get_features(devices_with_events, raw_data_dict, label='gender', has_events=True)\n",
        "  \n",
        "  y_gen_pred = cali_cfl.predict(X_data)\n",
        "  y_gen_pred_proba = cali_cfl.predict_proba(X_data)\n",
        "  \n",
        "  return y_gen_pred, y_gen_pred_proba\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "S-LLY0V_VyyR"
      },
      "outputs": [],
      "source": [
        "def predict_user_group_with_events(devices_with_events, predicted_gender, raw_data_dict):\n",
        "  print('Predicting user group using events data')\n",
        "  import pickle\n",
        "  file_name = f\"{drive_path}/best_model_group_with_events.pkl\"\n",
        "  X_data = get_features(devices_with_events, raw_data_dict, label='group', has_events=True)\n",
        "  X_data = hstack([X_data, predicted_gender])\n",
        "\n",
        "  cali_cfl = pickle.load(open(file_name, \"rb\"))\n",
        "  predict_y_proba = cali_cfl.predict_proba(X_data)\n",
        "  predict_y = cali_cfl.predict(X_data)\n",
        "  \n",
        "  print('classes: ', cali_cfl.classes_)\n",
        "\n",
        "  return predict_y, predict_y_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7ZcFbZkhXZoI"
      },
      "outputs": [],
      "source": [
        "def predict_gender_no_events(devices_no_events, raw_data_dict):\n",
        "  print('Predicting gender on devices with no events')\n",
        "  import pickle\n",
        "  file_name = f\"{drive_path}/best_model_gender_with_no_events.pkl\"\n",
        "  \n",
        "  X_data = get_features(devices_no_events, raw_data_dict, label='gender', has_events=False)\n",
        "    \n",
        "  cali_cfl = pickle.load(open(file_name, \"rb\"))\n",
        "  predict_y_test_proba = cali_cfl.predict_proba(X_data)\n",
        "  predict_y_test = cali_cfl.predict(X_data)\n",
        "\n",
        "  return predict_y_test, predict_y_test_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RuXhvemhYiL3"
      },
      "outputs": [],
      "source": [
        "def predict_user_groups_no_events(devices_no_events, predicted_gender, raw_data_dict):\n",
        "  print('Predicting user group on devices with no events')\n",
        "  import pickle\n",
        "  file_name = f\"{drive_path}/best_model_group_with_no_events.pkl\"\n",
        "    \n",
        "  X_data = get_features(devices_no_events, raw_data_dict, label='group', has_events=False)\n",
        "  X_data = hstack([X_data, predicted_gender])\n",
        "  \n",
        "  cali_cfl = pickle.load(open(file_name, \"rb\"))\n",
        "  predict_y_proba = cali_cfl.predict_proba(X_data)\n",
        "  predict_y = cali_cfl.predict(X_data)\n",
        "\n",
        "  return predict_y, predict_y_proba"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_user_group_events_nb(X_data, y_tr_events, training=False):\n",
        "#   import pickle\n",
        "#   file_name = f\"{drive_path}/best_model_group_predictor_with_events_nb.pkl\"\n",
        "\n",
        "#   if training:\n",
        "#     parameters = {'alpha': [0.00001, 0.0005, 0.0001, 0.005, 0.001, 0.05, 0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 1000, 10000]}\n",
        "  \n",
        "#     nb_clf = MultinomialNB()\n",
        "#     grid_search = GridSearchCV(nb_clf, parameters, cv=5, scoring='neg_log_loss', verbose=10, n_jobs=-1)\n",
        "#     grid_search.fit(X_data, y_tr_events)\n",
        "\n",
        "#     print('best params: ', grid_search.best_params_)\n",
        "\n",
        "#     nb_model = grid_search.best_estimator_\n",
        "\n",
        "#     sig_clf = CalibratedClassifierCV(nb_model, method=\"sigmoid\")\n",
        "#     sig_clf.fit(X_data, y_tr_events)\n",
        "\n",
        "#     y_pred = sig_clf.predict(X_data)\n",
        "#     y_pred_proba = sig_clf.predict_proba(X_data)\n",
        "\n",
        "#     # saving the model to disk for later usage\n",
        "#     pickle.dump(sig_clf, open(file_name, \"wb\"))\n",
        "#     return y_pred, y_pred_proba\n",
        "#   else:\n",
        "#     sig_clf = pickle.load(open(file_name, \"rb\"))\n",
        "#     y_pred = sig_clf.predict(X_data)\n",
        "#     y_pred_proba = sig_clf.predict_proba(X_data)\n",
        "#     return y_pred, y_pred_proba"
      ],
      "metadata": {
        "id": "p8rv0iZ3tAgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## final_func_1(), this method returns predicted labels and predicted probabilities "
      ],
      "metadata": {
        "id": "Jy5YPKYWtAp7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ha7YHI8nmAJ_"
      },
      "outputs": [],
      "source": [
        "def final_fun_1(devices, raw_data_dict, with_eval=False):\n",
        "  all_events_df = raw_data_dict.get('all_events')\n",
        "  is_events = model_training.has_events(devices, all_events_df)\n",
        "\n",
        "  final_y_pred_proba = np.zeros((devices.shape[0], 12))\n",
        "  final_y_pred = np.zeros(devices.shape[0])\n",
        "\n",
        "  devices_with_events = devices[is_events == 1]\n",
        "\n",
        "  # predicting gender on devices with events\n",
        "  y_gen_pred, y_gen_pred_proba = predict_gender_with_events(devices_with_events[['device_id']], raw_data_dict)\n",
        "  devices_with_events['gen_pred'] = y_gen_pred\n",
        "  devices_with_events[['gen_proba_1', 'gen_proba_2']] = y_gen_pred_proba\n",
        "\n",
        "  if with_eval:\n",
        "    y_gender_events_true = get_labels_(devices_with_events['gender'].values, label='gender')\n",
        "    print('Logloss for gender prediction with events data: ', log_loss(y_gender_events_true, y_gen_pred_proba))\n",
        "  \n",
        "  # predicting group on devices with events\n",
        "  y_with_events_pred, y_with_events_pred_proba = predict_user_group_with_events(devices_with_events[['device_id']], y_gen_pred_proba, raw_data_dict)\n",
        "  devices_with_events['pred_group'] = y_with_events_pred\n",
        "  devices_with_events[[f'pred_group_proba_{column}' for column in range(0, 12)]] = y_with_events_pred_proba\n",
        "\n",
        "  if with_eval:\n",
        "    y_group_events_true = get_labels_(devices_with_events['group'].values, label='group')\n",
        "    print('Logloss for user group prediction with events data: ', log_loss(y_group_events_true, y_with_events_pred_proba))\n",
        "\n",
        "  # storing predicted values in final_y_pred_proba and final_y_pred, at correct indexes, \n",
        "  # so that predicted values are in same order that of passed devices \n",
        "  with_events_prob_indx = np.expand_dims(np.where(is_events == 1)[0], axis=1)\n",
        "  np.put_along_axis(final_y_pred_proba, with_events_prob_indx, y_with_events_pred_proba, axis=0)\n",
        "  \n",
        "  with_events_indx = np.where(is_events == 1)[0]\n",
        "  np.put_along_axis(final_y_pred, with_events_indx, y_with_events_pred, axis=0)\n",
        "\n",
        "  devices_no_events = devices[is_events == 0]\n",
        "\n",
        "  # predicting gender on devices without events\n",
        "  y_gen_pred_no_events, y_gen_pred_no_events_proba = predict_gender_no_events(devices_no_events[['device_id']], raw_data_dict)\n",
        "  devices_no_events['gen_pred'] = y_gen_pred_no_events\n",
        "  devices_no_events[['gen_proba_1', 'gen_proba_2']] = y_gen_pred_no_events_proba\n",
        "\n",
        "  if with_eval:\n",
        "    y_gender_noevents_true = get_labels_(devices_no_events['gender'].values, label='gender')\n",
        "    print('Logloss for gender prediction without events data: ', log_loss(y_gender_noevents_true, y_gen_pred_no_events_proba))\n",
        "\n",
        "  # predicting gender on devices without events\n",
        "  y_pred_no_events, y_pred_no_events_proba = predict_user_groups_no_events(devices_no_events[['device_id']], y_gen_pred_no_events_proba, raw_data_dict)\n",
        "  devices_no_events['pred_group'] = y_pred_no_events\n",
        "  devices_no_events[[f'pred_group_proba_{column}' for column in range(0, 12)]] = y_pred_no_events_proba\n",
        "\n",
        "  if with_eval:\n",
        "    y_group_noevents_true = get_labels_(devices_no_events['group'].values, label='group')\n",
        "    print('Logloss for user group prediction without events data: ', log_loss(y_group_noevents_true, y_pred_no_events_proba))\n",
        "\n",
        "  no_events_indx_proba = np.expand_dims(np.where(is_events == 0)[0], axis=1)\n",
        "  np.put_along_axis(final_y_pred_proba, no_events_indx_proba, y_pred_no_events_proba, axis=0)\n",
        "\n",
        "  no_events_indx = np.where(is_events == 0)[0]\n",
        "  np.put_along_axis(final_y_pred, no_events_indx, y_pred_no_events, axis=0)\n",
        "\n",
        "  devices = devices.merge(devices_with_events, on='device_id', how='left').merge(devices_no_events, on='device_id', how='left')\n",
        "  print(devices.head())\n",
        "  return devices['pred_group'].values, devices['pred_group_proba'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## final_func_2(), this method returns log loss"
      ],
      "metadata": {
        "id": "dtumEdY7tam9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tMyAOzS99zPt"
      },
      "outputs": [],
      "source": [
        "def final_fun_2(devices, raw_data_dict):\n",
        "  all_events_df = raw_data_dict.get('all_events')\n",
        "  y_true = get_labels_(devices['group'].values, label='group')\n",
        "\n",
        "  y_pred, y_pred_proba = final_fun_1(devices, raw_data_dict, with_eval=True)\n",
        "  print(len(y_true))\n",
        "  print(len(y_pred_proba))\n",
        "  return log_loss(y_true, y_pred_proba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5wKJtM61o5X9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a369c2cc-ad9c-4395-8ca8-9f21dabeaf2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting gender using events data\n",
            "distance travelled  (23309, 9)\n",
            "data shape before removing no variance data:  (23309, 4591)\n",
            "data shape (23309, 2843)\n",
            "Logloss for gender prediction with events data:  0.45691175448394333\n",
            "Predicting user group using events data\n",
            "distance travelled  (23309, 9)\n",
            "data shape before removing no variance data:  (23309, 4591)\n",
            "data shape (23309, 2842)\n",
            "Logloss for user group prediction with events data:  1.8396423837234026\n",
            "Predicting gender on devices with no events\n",
            "data shape before removing no var data:  (51336, 1731)\n",
            "data shape (51336, 1043)\n",
            "Logloss for gender prediction without events data:  0.6285619334348501\n",
            "Predicting user group on devices with no events\n",
            "data shape before removing no var data:  (51336, 1751)\n",
            "data shape (51336, 1068)\n",
            "Logloss for user group prediction without events data:  2.2915588224168753\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 8.,  7., 10., ..., 10.,  7.,  7.]),\n",
              " array([[0.04547512, 0.05536524, 0.03763794, ..., 0.09790811, 0.12324675,\n",
              "         0.08764882],\n",
              "        [0.04824545, 0.07218755, 0.03882167, ..., 0.10708565, 0.13826961,\n",
              "         0.09667036],\n",
              "        [0.14991827, 0.0527382 , 0.0436365 , ..., 0.10408701, 0.16573645,\n",
              "         0.10779792],\n",
              "        ...,\n",
              "        [0.06418519, 0.05895201, 0.0390226 , ..., 0.10050034, 0.12459151,\n",
              "         0.11046935],\n",
              "        [0.04569494, 0.04571339, 0.0331571 , ..., 0.10314492, 0.19358975,\n",
              "         0.05878446],\n",
              "        [0.03836587, 0.04205361, 0.03883689, ..., 0.14967962, 0.17404905,\n",
              "         0.06732349]]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "devices = pd.read_csv('data/gender_age_train.csv')\n",
        "\n",
        "raw_data_dict = {\n",
        "    'all_events': pd.read_csv('data/events.csv'),\n",
        "    'all_app_events': pd.read_csv('data/app_events.csv'),\n",
        "    'app_labels':  pd.read_csv('data/app_labels.csv'),\n",
        "    'label_categories': pd.read_csv('data/label_categories.csv'),\n",
        "    'phone_brand':  pd.read_csv('data/phone_brand_device_model.csv')\n",
        "}\n",
        "\n",
        "final_fun_1(devices, raw_data_dict, with_eval=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Hss-FkH-7Xl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "420f3577-469e-47f6-c1f7-af09da90e82c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting gender using events data\n",
            "distance travelled  (23309, 9)\n",
            "data shape before removing no variance data:  (23309, 4591)\n",
            "data shape (23309, 2843)\n",
            "Logloss for gender prediction with events data:  0.45691175448394333\n",
            "Predicting user group using events data\n",
            "distance travelled  (23309, 9)\n",
            "data shape before removing no variance data:  (23309, 4591)\n",
            "data shape (23309, 2842)\n",
            "Logloss for user group prediction with events data:  1.8396423837234026\n",
            "Predicting gender on devices with no events\n",
            "data shape before removing no var data:  (51336, 1731)\n",
            "data shape (51336, 1043)\n",
            "Logloss for gender prediction without events data:  0.6285619334348501\n",
            "Predicting user group on devices with no events\n",
            "data shape before removing no var data:  (51336, 1751)\n",
            "data shape (51336, 1068)\n",
            "Logloss for user group prediction without events data:  2.2915588224168753\n",
            "74645\n",
            "74645\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.1504412623725835"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "devices = pd.read_csv('data/gender_age_train.csv')\n",
        "\n",
        "raw_data_dict = {\n",
        "    'all_events': pd.read_csv('data/events.csv'),\n",
        "    'all_app_events': pd.read_csv('data/app_events.csv'),\n",
        "    'app_labels':  pd.read_csv('data/app_labels.csv'),\n",
        "    'label_categories': pd.read_csv('data/label_categories.csv'),\n",
        "    'phone_brand':  pd.read_csv('data/phone_brand_device_model.csv')\n",
        "}\n",
        "\n",
        "final_fun_2(devices, raw_data_dict, with_eval=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observation"
      ],
      "metadata": {
        "id": "vyOwoLSKq9Bv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   final_func_2 returns the result log loss on training data is : 2.1519659987248203\n",
        "\n"
      ],
      "metadata": {
        "id": "RGLuzq8Qq109"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "devices = pd.read_csv('data/gender_age_test.csv')\n",
        "\n",
        "raw_data_dict = {\n",
        "    'all_events': pd.read_csv('data/events.csv'),\n",
        "    'all_app_events': pd.read_csv('data/app_events.csv'),\n",
        "    'app_labels':  pd.read_csv('data/app_labels.csv'),\n",
        "    'label_categories': pd.read_csv('data/label_categories.csv'),\n",
        "    'phone_brand':  pd.read_csv('data/phone_brand_device_model.csv')\n",
        "}\n",
        "\n",
        "y_pred, y_pred_proba = final_fun_1(devices, raw_data_dict)\n",
        "result = pd.DataFrame(y_pred_proba, index=devices.device_id, columns=get_labels_([0,1,2,3,4,5,6,7,8,9,10,11], inverse=True))\n",
        "result.head()\n",
        "result.to_csv('submission_file.csv')"
      ],
      "metadata": {
        "id": "4-jgDyoaZR1I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c594c71-6316-44f4-ae5a-0d4f49ee9701"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting gender using events data\n",
            "distance travelled  (35194, 9)\n",
            "data shape before removing no variance data:  (35194, 4591)\n",
            "data shape (35194, 2843)\n",
            "Predicting user group using events data\n",
            "distance travelled  (35194, 9)\n",
            "data shape before removing no variance data:  (35194, 4591)\n",
            "data shape (35194, 2842)\n",
            "classes:  [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
            "Predicting gender on devices with no events\n",
            "data shape before removing no var data:  (76877, 1731)\n",
            "data shape (76877, 1043)\n",
            "Predicting user group on devices with no events\n",
            "data shape before removing no var data:  (76877, 1751)\n",
            "data shape (76877, 1068)\n",
            "             device_id  gen_pred_x  gen_proba_1_x  gen_proba_2_x  \\\n",
            "0  1002079943728939269         1.0       0.114819       0.885181   \n",
            "1 -1547860181818787117         1.0       0.255693       0.744307   \n",
            "2  7374582448058474277         0.0       0.677073       0.322927   \n",
            "3 -6220210354783429585         1.0       0.138893       0.861107   \n",
            "4 -5893464122623104785         NaN            NaN            NaN   \n",
            "\n",
            "   pred_group_x  pred_group_proba_0_x  pred_group_proba_1_x  \\\n",
            "0          11.0              0.024724              0.027188   \n",
            "1          11.0              0.029106              0.035492   \n",
            "2           3.0              0.045273              0.046114   \n",
            "3          11.0              0.026598              0.035996   \n",
            "4           NaN                   NaN                   NaN   \n",
            "\n",
            "   pred_group_proba_2_x  pred_group_proba_3_x  pred_group_proba_4_x  ...  \\\n",
            "0              0.027014              0.038498              0.039749  ...   \n",
            "1              0.030766              0.071088              0.073453  ...   \n",
            "2              0.034126              0.155780              0.153558  ...   \n",
            "3              0.028140              0.041454              0.051460  ...   \n",
            "4                   NaN                   NaN                   NaN  ...   \n",
            "\n",
            "   pred_group_proba_2_y  pred_group_proba_3_y  pred_group_proba_4_y  \\\n",
            "0                   NaN                   NaN                   NaN   \n",
            "1                   NaN                   NaN                   NaN   \n",
            "2                   NaN                   NaN                   NaN   \n",
            "3                   NaN                   NaN                   NaN   \n",
            "4              0.039557               0.06027              0.051531   \n",
            "\n",
            "   pred_group_proba_5_y  pred_group_proba_6_y  pred_group_proba_7_y  \\\n",
            "0                   NaN                   NaN                   NaN   \n",
            "1                   NaN                   NaN                   NaN   \n",
            "2                   NaN                   NaN                   NaN   \n",
            "3                   NaN                   NaN                   NaN   \n",
            "4              0.043691              0.077621              0.185841   \n",
            "\n",
            "   pred_group_proba_8_y  pred_group_proba_9_y  pred_group_proba_10_y  \\\n",
            "0                   NaN                   NaN                    NaN   \n",
            "1                   NaN                   NaN                    NaN   \n",
            "2                   NaN                   NaN                    NaN   \n",
            "3                   NaN                   NaN                    NaN   \n",
            "4              0.095243              0.104121               0.124428   \n",
            "\n",
            "   pred_group_proba_11_y  \n",
            "0                    NaN  \n",
            "1                    NaN  \n",
            "2                    NaN  \n",
            "3                    NaN  \n",
            "4               0.095647  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'pred_group'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-9461d36624d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_fun_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_labels_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-d396fbda4db9>\u001b[0m in \u001b[0;36mfinal_fun_1\u001b[0;34m(devices, raw_data_dict, with_eval)\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices_with_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'device_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices_no_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'device_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_group'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_group_proba'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'pred_group'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Final.ipynb",
      "provenance": [],
      "mount_file_id": "1j_1dfd89b_XAARkLMIxedOMaVviXCR_z",
      "authorship_tag": "ABX9TyNgduKjEQk1ikNo6TeOU/58",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}